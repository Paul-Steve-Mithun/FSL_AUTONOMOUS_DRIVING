{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-Steve-Mithun/FSL_AUTONOMOUS_DRIVING/blob/main/FSL_TRAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RdFqT_JP_nq",
        "outputId": "55fa3609-51de-4e00-e08e-471b6fdc16af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Collecting torch-lr-finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easyfsl\n",
            "  Downloading easyfsl-1.5.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (1.25.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (4.66.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (24.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->easyfsl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->easyfsl) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.1->torch-lr-finder)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->torch-lr-finder)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->torch-lr-finder) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->torch-lr-finder) (1.3.0)\n",
            "Installing collected packages: torch-summary, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-lr-finder, timm, easyfsl\n",
            "Successfully installed easyfsl-1.5.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-1.0.7 torch-lr-finder-0.2.1 torch-summary-1.4.5\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-summary torch-lr-finder timm easyfsl\n",
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "from easyfsl.samplers import TaskSampler\n",
        "from easyfsl.utils import plot_images, sliding_average\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Set the path to your dataset\n",
        "data_path = '/content/drive/MyDrive/datasets/Steve_Dataset'  # Adjust this path\n",
        "\n",
        "# Check the classes in the dataset\n",
        "class_name = os.listdir(data_path)\n",
        "print(class_name)\n"
      ],
      "metadata": {
        "id": "NjIPVW7bK-f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c3ce35-739f-4f6c-f91f-d3927481501c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['Car', 'Truck', 'Bike', 'Pedestrians']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PrototypicalNetworks(nn.Module):\n",
        "    def __init__(self, backbone: nn.Module):\n",
        "        super(PrototypicalNetworks, self).__init__()\n",
        "        self.backbone = backbone\n",
        "\n",
        "    def forward(self, support_images: torch.Tensor, support_labels: torch.Tensor, query_images: torch.Tensor) -> torch.Tensor:\n",
        "        z_support = self.backbone.forward(support_images)\n",
        "        z_query = self.backbone.forward(query_images)\n",
        "        n_way = len(torch.unique(support_labels))\n",
        "        z_proto = torch.cat([z_support[torch.nonzero(support_labels == label)].mean(0) for label in range(n_way)])\n",
        "        dists = torch.cdist(z_query, z_proto)\n",
        "        scores = -dists\n",
        "        return scores\n",
        "\n",
        "# Use ResNet-50 as the backbone\n",
        "convolutional_network = resnet50(pretrained=True)\n",
        "convolutional_network.fc = nn.Flatten()\n",
        "model = PrototypicalNetworks(convolutional_network)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XBZOAlAkvcH",
        "outputId": "96bada71-57c8-4290-aca6-57e9d4c7edb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 129MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrototypicalNetworks(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        self.class_names = sorted(os.listdir(data_path))\n",
        "        for label, class_name in enumerate(self.class_names):\n",
        "            current_folder = os.path.join(data_path, class_name)\n",
        "            for i, file in enumerate(os.listdir(current_folder)):\n",
        "                fullpath = os.path.join(current_folder, file)\n",
        "\n",
        "                # Check if the image can be opened and loaded successfully\n",
        "                try:\n",
        "                    # Attempt to open and load the image\n",
        "                    with Image.open(fullpath) as im:\n",
        "                        im.load()  # Force loading the image data\n",
        "\n",
        "                    self.images.append(fullpath)\n",
        "                    self.labels.append(label)\n",
        "                except IOError:\n",
        "                    print(f\"Skipping corrupted image: {fullpath}\")  # Log the skipped image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        # Open image within a try-except block to catch potential errors\n",
        "        try:\n",
        "            image = Image.open(img_path)\n",
        "        except IOError:\n",
        "            print(f\"Error opening image: {img_path}\")\n",
        "            return None, None  # Return None for both image and label if error\n",
        "\n",
        "        # Check if image is palette with transparency\n",
        "        if image.mode == 'P' and 'transparency' in image.info:\n",
        "            image = image.convert('RGBA')\n",
        "\n",
        "        image = image.convert('RGB')  # Ensure RGB format for consistency\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "N_WAY = 4  # Number of classes in a task\n",
        "N_SHOT = 15  # Number of images per class in the support set\n",
        "N_QUERY = 1  # Number of images per class in the query set\n",
        "N_EVALUATION_TASKS = 50\n",
        "\n",
        "test_set = CustomDataset(data_path, transform=transform)\n",
        "test_set.get_labels = lambda: [instance[1] for instance in zip(test_set.images, test_set.labels)]\n",
        "\n",
        "test_sampler = TaskSampler(\n",
        "    test_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_sampler=test_sampler,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=test_sampler.episodic_collate_fn,\n",
        ")\n"
      ],
      "metadata": {
        "id": "FCvDtJzolq4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate one task\n",
        "def evaluate_on_one_task(support_images: torch.Tensor, support_labels: torch.Tensor, query_images: torch.Tensor, query_labels: torch.Tensor) -> [int, int]:\n",
        "    support_images = support_images.to(device)\n",
        "    support_labels = support_labels.to(device)\n",
        "    query_images = query_images.to(device)\n",
        "    query_labels = query_labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(support_images, support_labels, query_images)\n",
        "    predicted_labels = torch.max(output, 1)[1]\n",
        "    correct_predictions = (predicted_labels == query_labels).sum().item()\n",
        "    return correct_predictions, len(query_labels)\n",
        "\n",
        "# Function to evaluate the entire dataset\n",
        "def evaluate(data_loader: DataLoader):\n",
        "    total_predictions = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for episode_index, (support_images, support_labels, query_images, query_labels, _) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            correct, total = evaluate_on_one_task(support_images, support_labels, query_images, query_labels)\n",
        "            total_predictions += total\n",
        "            correct_predictions += correct\n",
        "\n",
        "    accuracy = 100 * correct_predictions / total_predictions\n",
        "    print(f\"Model tested on {len(data_loader)} tasks. Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "# Load the checkpoint\n",
        "def load_checkpoint(file_path, model):\n",
        "    checkpoint = torch.load(file_path, map_location=torch.device('cpu'))  # Use appropriate device if not using CPU\n",
        "    # Handle missing keys\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "\n",
        "    if missing_keys:\n",
        "        print(\"Warning: Missing keys in state_dict:\", missing_keys)\n",
        "    if unexpected_keys:\n",
        "        print(\"Warning: Unexpected keys in state_dict:\", unexpected_keys)\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    mean_accuracy = checkpoint['mean_accuracy']\n",
        "    std_accuracy = checkpoint['std_accuracy']\n",
        "    print(f\"Checkpoint loaded from epoch {epoch} with mean accuracy: {mean_accuracy:.2f}%\")\n",
        "    return epoch, mean_accuracy, std_accuracy\n"
      ],
      "metadata": {
        "id": "4vcMrHI5ircJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Path to your saved checkpoint file\n",
        "save_path = '/content/drive/MyDrive/prototypical_networks_evalmodel1.pth'\n",
        "\n",
        "# Example usage to load the checkpoint\n",
        "loaded_epoch, loaded_mean_accuracy, loaded_std_accuracy = load_checkpoint(save_path, model)\n",
        "\n",
        "# Now you can continue evaluating your model or resume training from this point\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcpRKDxfIhBZ",
        "outputId": "ee478f6e-8e23-462c-d35d-6cb79e112ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded from epoch 10 with mean accuracy: 92.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader):\n",
        "        support_images, support_labels, query_images, query_labels, _ = batch\n",
        "\n",
        "        support_images = support_images.to(device)\n",
        "        support_labels = support_labels.to(device)\n",
        "        query_images = query_images.to(device)\n",
        "        query_labels = query_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(support_images, support_labels, query_images)\n",
        "        loss = criterion(output, query_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for param in convolutional_network.parameters():\n",
        "    param.requires_grad = True  # Unfreeze all layers for fine-tuning\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    avg_loss = train(model, test_loader, optimizer, criterion, device)\n",
        "    print(f\"Epoch [{epoch+1}/10], Loss: {avg_loss:.4f}\")\n",
        "    scheduler.step()\n",
        "    evaluate(test_loader)\n"
      ],
      "metadata": {
        "id": "0EWwjj8ogx8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7acb6e-9a96-4262-a949-c8cd46fa31fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [01:55<1:34:18, 115.49s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/FSL_FinalModel.pth'  # Adjust the path as needed\n",
        "\n",
        "# Function to save the checkpoint\n",
        "def save_checkpoint(model, optimizer, epoch, mean_accuracy, std_accuracy, file_path):\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'mean_accuracy': mean_accuracy,\n",
        "        'std_accuracy': std_accuracy\n",
        "    }\n",
        "    torch.save(checkpoint, file_path)\n",
        "    print(f\"Checkpoint saved at epoch {epoch} with mean accuracy: {mean_accuracy:.2f}%\")\n",
        "\n",
        "# Assuming `mean_accuracy` and `std_accuracy` are calculated during evaluation\n",
        "# Evaluate the model to get accuracy\n",
        "mean_accuracy = evaluate(test_loader)\n",
        "std_accuracy = 0  # If you do not calculate std accuracy, set it to 0 or appropriate value\n",
        "\n",
        "# Save the checkpoint\n",
        "save_checkpoint(model, optimizer, epoch=20, mean_accuracy=mean_accuracy, std_accuracy=std_accuracy, file_path=save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx6vGV_QuGAW",
        "outputId": "b272010b-7a98-448e-b5a8-266108072898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [02:37<00:00,  1.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model tested on 100 tasks. Accuracy: 96.75%\n",
            "Checkpoint saved at epoch 20 with mean accuracy: 96.75%\n"
          ]
        }
      ]
    }
  ]
}